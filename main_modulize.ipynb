{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 參數設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-08-29T08:17:54.085836Z",
          "start_time": "2022-08-29T08:17:54.051184Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "load_dotenv('/eason/.server.env')\n",
        "\n",
        "import pymongo\n",
        "MongoClient = pymongo.MongoClient(f\"mongodb://{os.getenv('mongo_user')}:{os.getenv('mongo_pw')}@localhost:27081\")\n",
        "\n",
        "DB_NAME = \"chatbot_experiment_2022_09\"\n",
        "GPT3_chat_history_col = MongoClient[DB_NAME][\"GPT3_Chat\"]\n",
        "GPT3_chat_user_col = MongoClient[DB_NAME][\"Users\"]\n",
        "GPT3_chat_bots_col = MongoClient[DB_NAME][\"Bots\"]\n",
        "\n",
        "\n",
        "from translate import translate\n",
        "\n",
        "from linebot import (\n",
        "    LineBotApi, WebhookHandler\n",
        ")\n",
        "from linebot.exceptions import (\n",
        "    InvalidSignatureError\n",
        ")\n",
        "from linebot.models import (\n",
        "    MessageEvent,\n",
        "    TextMessage,\n",
        "    TextSendMessage,\n",
        "    FlexSendMessage,\n",
        "    TemplateSendMessage,\n",
        "    MessageTemplateAction,\n",
        "    ButtonsTemplate,\n",
        "    PostbackEvent,\n",
        "    PostbackTemplateAction,\n",
        "    AudioMessage,\n",
        "    AudioSendMessage,\n",
        "    Sender\n",
        ")\n",
        "\n",
        "from flask import Flask, request, abort, render_template, send_from_directory\n",
        "import subprocess\n",
        "\n",
        "\n",
        "\n",
        "app = Flask(__name__, template_folder = 'dist')\n",
        "\n",
        "line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))\n",
        "handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 處理 GPT 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-08-29T08:17:54.425963Z",
          "start_time": "2022-08-29T08:17:54.330326Z"
        }
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "from google.cloud import speech\n",
        "import sys, pathlib\n",
        "from pydub import AudioSegment\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import uuid\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "import io\n",
        "def voice_reco(client, filename):\n",
        "    with io.open(filename, \"rb\") as audio_file:\n",
        "        content = audio_file.read()\n",
        "    audio = speech.RecognitionAudio(content = content)\n",
        "\n",
        "\n",
        "    config = speech.RecognitionConfig(\n",
        "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "        sample_rate_hertz=16000,\n",
        "        language_code=\"zh-TW\"\n",
        "    )\n",
        "    response = client.recognize(config=config, audio=audio)\n",
        "    try:\n",
        "        text = response.results[0].alternatives[0].transcript\n",
        "    except:\n",
        "        text = \"\"\n",
        "    return text\n",
        "\n",
        "def process_voice_file(file_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        # Instantiates a client\n",
        "        client = speech.SpeechClient.from_service_account_json(os.getenv('GOOGLE_SERVICE_JSON_PATH'))\n",
        "        # Detects speech in the audio file\n",
        "        wav = AudioSegment.from_wav(f'{file_path}.wav')\n",
        "        if wav.duration_seconds < 60:\n",
        "            text = voice_reco(client, f'{file_path}.wav')\n",
        "\n",
        "            all_texts = [text]\n",
        "        else:\n",
        "            text = \"too long... can't recognize...\"\n",
        "            wav_files = []\n",
        "            while wav.duration_seconds > 60:\n",
        "                temp_filename = str(uuid.uuid4())\n",
        "                temp_filename = f'{file_path}.wav'\n",
        "                slice_wav = wav[0:59]\n",
        "                slice_wav.export(temp_filename, format=\"wav\")\n",
        "                wav_files.append(temp_filename)\n",
        "                wav = wav[57:]\n",
        "            temp_filename = str(uuid.uuid4())\n",
        "            temp_filename = f'{file_path}.wav'\n",
        "            wav.export(temp_filename, format=\"wav\")\n",
        "            wav_files.append(temp_filename)\n",
        "            all_texts = []\n",
        "            for wav_file in wav_files:\n",
        "                text = voice_reco(client, wav_file)\n",
        "                all_texts.append(text)\n",
        "                os.remove(wav_file)\n",
        "\n",
        "            #response = client.long_running_recognize(config=config, audio=audio)\n",
        "            #response = operation.result(timeout=90)\n",
        "            #text = response.results[0].alternatives[0].transcript\n",
        "        #AAA.append(response)\n",
        "        text = \"\".join(all_texts)\n",
        "        \n",
        "\n",
        "        os.remove(f'{file_path}.wav')\n",
        "        os.remove(f'{file_path}')\n",
        "    except ValueError as e:\n",
        "        import traceback\n",
        "        import sys\n",
        "        exc_type, exc_value, exc_tb = sys.exc_info()\n",
        "        text = \"[ERROR]\\n\" + \"\".join(traceback.format_exception(exc_type, exc_value, exc_tb))\n",
        "        '''if update.message.chat.id in User_List:\n",
        "            result = \"[ERROR]\\n\" + \"\".join(traceback.format_exception(exc_type, exc_value, exc_tb))\n",
        "            bot.edit_message_text(text = result, message_id=reply_msg.message_id, chat_id= reply_msg.chat_id)\n",
        "        else:\n",
        "            result = \"Error, Might be no detectable text in the voice message. If you think this is an error otherwise, please contect the author @EasonC13\"\n",
        "            bot.edit_message_text(text = result, message_id=reply_msg.message_id, chat_id= reply_msg.chat_id)'''\n",
        "        \n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "def process_voice_message(event):\n",
        "    #AAA.append(event)\n",
        "    file_path = f'/tmp/{uuid.uuid4()}'\n",
        "    \n",
        "    message_content = line_bot_api.get_message_content(event.message.id)\n",
        "\n",
        "    with open(file_path, 'wb') as fd:\n",
        "        for chunk in message_content.iter_content():\n",
        "            fd.write(chunk)\n",
        "\n",
        "    subprocess.call(\n",
        "            f'ffmpeg -i {file_path} {file_path}.wav',\n",
        "            shell=True, stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.STDOUT)\n",
        "\n",
        "    text = process_voice_file(file_path)\n",
        "    send_GPT3_response(text = text, event = event)\n",
        "\n",
        "from bson.objectid import ObjectId\n",
        "def create_prompt(prompt, prev_msgs, text, num = -3):\n",
        "    prompt = (prompt + \"\\n\") if prompt[-1] != \"\\n\" else prompt\n",
        "    for msg in prev_msgs[num:]:\n",
        "        prompt += f\"You: {msg['input_text_en']}\\nFriend: {msg['response_text_en']}\\n\"\n",
        "    prompt += f\"You: {text}\\nFriend: \"\n",
        "    return prompt\n",
        "\n",
        "#以棄用\n",
        "def update_pre_prompt():\n",
        "    \"\"\"def update_pre_prompt(user_id, text):\n",
        "        GPT3_chat_user_col.update_one({\n",
        "                \"user_id\": user_id\n",
        "            },{\n",
        "                \"$set\": {\"pre_prompt\": text}\n",
        "            })\n",
        "\n",
        "    def update_chat_with(user_id, chat_with, chat_from = \"You\"):\n",
        "        GPT3_chat_user_col.update_one({\n",
        "                \"user_id\": user_id\n",
        "            },{\"$set\":{\n",
        "                \"chat_with\": chat_with,\n",
        "                \"chat_from\": chat_from,\n",
        "            }})\"\"\"\n",
        "pass\n",
        "\n",
        "def generate_GPT3_response(event, text, bot):\n",
        "    \n",
        "    user = get_user(event.source.user_id)\n",
        "    \n",
        "    prev_msgs = GPT3_chat_history_col.find({\n",
        "        'user.user_id': event.source.user_id,\n",
        "        'user.sn': user['sn'], #serial number\n",
        "        'bot_id': bot['id'],\n",
        "    })\n",
        "    prev_msgs = list(prev_msgs)\n",
        "    prev_msgs.sort(key=lambda x: x['time'])\n",
        "    \n",
        "    prompt = create_prompt(bot['prefix'], prev_msgs, text, -3)\n",
        "    \n",
        "    have_second_chance = True\n",
        "    max_try = 4\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-001\",\n",
        "      prompt=prompt,\n",
        "      temperature=0.6,\n",
        "      max_tokens=120,\n",
        "      top_p=1.0,\n",
        "      frequency_penalty=0.5,\n",
        "      presence_penalty=0.5,\n",
        "      stop=[\"You:\"]\n",
        "    )\n",
        "\n",
        "    response_text = response.choices[0].text.replace(\"\\n\", \"\")\n",
        "\n",
        "    prev_responses = list(map(lambda x: x['response_text_en'], prev_msgs[-3:]))\n",
        "    count = np.unique(prev_responses, return_counts=True)[1]\n",
        "    \n",
        "    print(prompt + response_text, end = '\\n')\n",
        "    \n",
        "    return response_text\n",
        "\n",
        "def norm_text(text):\n",
        "    text = text.replace(\"&#39;\", \"'\")\n",
        "    return text\n",
        "\n",
        "def get_bots(bot_id):\n",
        "    return GPT3_chat_bots_col.find_one({'id': bot_id})\n",
        "\n",
        "def send_GPT3_response(text, event):\n",
        "    \n",
        "    user = get_user(event.source.user_id)\n",
        "    user_profile = line_bot_api.get_profile(event.source.user_id)\n",
        "    \n",
        "    translated_result = translate(text, target=\"en\")\n",
        "    \n",
        "    text_en = translated_result['translatedText']\n",
        "    text_en = norm_text(text_en)\n",
        "    text_source = translated_result['detectedSourceLanguage']\n",
        "    if text_source == 'und':\n",
        "        text_source = \"zh-tw\"\n",
        "    \n",
        "    bots_id = user['bots']\n",
        "    if len(bots_id) == 0:\n",
        "        bots_id = ['棒男孩']\n",
        "    bots = list(map(get_bots, bots_id))\n",
        "    \n",
        "    message = []\n",
        "    tasks = [] #TODO: 如果需要照順序回要改成寫 mapping\n",
        "    for bot in bots:\n",
        "        t = doThreading(thread_GPT3, args = (message, event, text, text_en, bot, user_profile, user, text_source))\n",
        "        tasks.append(t)\n",
        "        #thread_GPT3(message, event, text, text_en, bot, user_profile, user, text_source)\n",
        "    for t in tasks:\n",
        "        t.join()\n",
        "\n",
        "    print(message)\n",
        "    line_bot_api.reply_message(event.reply_token, message)\n",
        "\n",
        "\n",
        "def thread_GPT3(message, event, text, text_en, bot, user_profile, user, text_source):\n",
        "    response_text = \"\"\n",
        "    while response_text == \"\":\n",
        "        response_text_en = generate_GPT3_response(event, text_en, bot)\n",
        "        response_text_en = norm_text(response_text_en)\n",
        "        print(f\"response_text_en = {response_text_en}, text_source = {text_source}\")\n",
        "\n",
        "        if text_source[:2] == \"zh\":\n",
        "            response_text = translate(response_text_en, target=\"zh-TW\")['translatedText']\n",
        "        elif text_source != 'en':\n",
        "            response_text = translate(response_text_en, target=text_source)['translatedText']\n",
        "        else:\n",
        "            response_text = response_text_en\n",
        "\n",
        "    print(\"----\")\n",
        "    print(f\"From: {bot['id']}\")\n",
        "    print('--Origin--')\n",
        "    print(f'{text_en} => {response_text_en}')\n",
        "    print('--Translated--')\n",
        "    print(f'{text} => {response_text}')\n",
        "    print('========')\n",
        "\n",
        "\n",
        "    GPT3_chat_history_col.insert_one({\n",
        "        'input_text': text,\n",
        "        'input_text_en': text_en,\n",
        "        'response_text_en': response_text_en,\n",
        "        'response_text': response_text,\n",
        "        'event_message_id': event.message.id,\n",
        "        'user': {\n",
        "            \"display_name\": user_profile.display_name,\n",
        "            \"user_id\": event.source.user_id,\n",
        "            \"sn\": user['sn'],\n",
        "        },\n",
        "        'bot_id': bot['id'],\n",
        "        \"time\": datetime.datetime.now(),\n",
        "        \"input_type\": 'text',\n",
        "    })\n",
        "\n",
        "    message.append(\n",
        "        TextSendMessage(\n",
        "            text=response_text, \n",
        "            sender = Sender(name = bot['name'].replace(\"_\", \" \"),\n",
        "                            icon_url = bot['img_url']))\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 回應邏輯"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-08-29T08:17:54.518920Z",
          "start_time": "2022-08-29T08:17:54.515241Z"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "ALL_STATUS = [\n",
        "            \"New Starter\",\n",
        "            \"Ready to go\",\n",
        "            \"Condition_A_Pretest\",\n",
        "            \"Condition_A_Chatting\",\n",
        "            \"Condition_A_Posttest\",\n",
        "            \"Condition_A_Finish\",\n",
        "            \"Condition_B_Pretest\",\n",
        "            \"Condition_B_Chatting\",\n",
        "            \"Condition_B_Posttest\",\n",
        "            \"Condition_B_Finish\",\n",
        "            \"Condition_C_Pretest\",\n",
        "            \"Condition_C_Chatting\",\n",
        "            \"Condition_C_Posttest\",\n",
        "            \"Condition_C_Finish\",            \n",
        "            \"Final_Test\"\n",
        "        ]\n",
        "def get_user(user_id):\n",
        "    user_profile = line_bot_api.get_profile(user_id)\n",
        "\n",
        "    user = GPT3_chat_user_col.find_one({\n",
        "        'user_id': user_id\n",
        "    })\n",
        "    if user == None:\n",
        "        user = {\n",
        "            'user_id': user_id,\n",
        "            'display_name': user_profile.display_name,\n",
        "            'sn': 0,\n",
        "            'status': ALL_STATUS[0],\n",
        "            'status_history': []\n",
        "        }\n",
        "        GPT3_chat_user_col.insert_one(user)\n",
        "\n",
        "    return user\n",
        "\n",
        "def process_text_message(event):\n",
        "    text = event.message.text\n",
        "    \n",
        "    if process_command(event, text):\n",
        "        return True\n",
        "    \n",
        "    send_GPT3_response(text, event)\n",
        "\n",
        "def update_user_status(user_id, newStatus):\n",
        "    user = GPT3_chat_user_col.find_one({\n",
        "            'user_id': user_id\n",
        "        })\n",
        "    GPT3_chat_user_col.update_one({\n",
        "        'user_id': user_id\n",
        "    }, {\n",
        "        '$set': {'status': newStatus},\n",
        "        '$push': {'status_history': user['status']}\n",
        "    })\n",
        "\n",
        "user = get_user(\"Ub830fb81ec2de64d825b4ab2f6b7472e\")\n",
        "\n",
        "user\n",
        "\n",
        "import random\n",
        "\n",
        "def randomly_assign_next_task(user):\n",
        "    tasks = [\"Condition_A_Pretest\", \"Condition_B_Pretest\", \"Condition_C_Pretest\"]\n",
        "    random.shuffle(tasks)\n",
        "    tasks.append(False)\n",
        "    for t in tasks:\n",
        "        if t not in user['status_history']:\n",
        "            break\n",
        "    if t:\n",
        "        update_user_status(user['user_id'], t)\n",
        "        return t\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def send_pre_test_info(event, user, tast_name):\n",
        "    line_bot_api.reply_message(event.reply_token, FlexSendMessage(\n",
        "        alt_text = f\"歡迎來到此聊天機器人實驗，請先點選下方連結閱讀實驗指引並確認開始實驗\\n\\nhttps://exp1.eason.best/starter?id={user['user_id']}\\n\\n完成後請點選「完成」\", \n",
        "        contents = {\n",
        "        \"type\": \"bubble\",\n",
        "        \"hero\": {\n",
        "        \"type\": \"image\",\n",
        "        \"url\": \"https://i.imgur.com/ufIifp6.png\",\n",
        "        \"size\": \"full\",\n",
        "        \"aspectRatio\": \"20:13\",\n",
        "        \"aspectMode\": \"cover\",\n",
        "        },\n",
        "        \"body\": {\n",
        "        \"type\": \"box\",\n",
        "        \"layout\": \"vertical\",\n",
        "        \"contents\": [\n",
        "          {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"前測\",\n",
        "            \"weight\": \"bold\",\n",
        "            \"size\": \"xl\"\n",
        "          },\n",
        "          {\n",
        "            \"type\": \"box\",\n",
        "            \"layout\": \"vertical\",\n",
        "            \"margin\": \"lg\",\n",
        "            \"spacing\": \"sm\",\n",
        "            \"contents\": [\n",
        "              {\n",
        "                \"type\": \"box\",\n",
        "                \"layout\": \"baseline\",\n",
        "                \"spacing\": \"sm\",\n",
        "                \"contents\": [\n",
        "                  {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"點選下方「進行前測」做好感度評估，之後點選「下一步」繼續實驗\",\n",
        "                    \"wrap\": True,\n",
        "                    \"color\": \"#666666\",\n",
        "                    \"size\": \"sm\",\n",
        "                    \"flex\": 5\n",
        "                  }\n",
        "                ]\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        ]\n",
        "        },\n",
        "        \"footer\": {\n",
        "        \"type\": \"box\",\n",
        "        \"layout\": \"vertical\",\n",
        "        \"spacing\": \"sm\",\n",
        "        \"contents\": [\n",
        "          {\n",
        "            \"type\": \"button\",\n",
        "            \"style\": \"link\",\n",
        "            \"height\": \"sm\",\n",
        "            \"action\": {\n",
        "              \"type\": \"uri\",\n",
        "              \"label\": \"進行前測\",\n",
        "              \"uri\": f\"https://exp1.eason.best/pretest?id=userid&test={tast_name}\"\n",
        "            }\n",
        "          },\n",
        "          {\n",
        "            \"type\": \"button\",\n",
        "            \"style\": \"link\",\n",
        "            \"height\": \"sm\",\n",
        "            \"action\": {\n",
        "              \"type\": \"message\",\n",
        "              \"label\": \"下一步\",\n",
        "              \"text\": \"我已完成前測\"\n",
        "            }\n",
        "          },\n",
        "          {\n",
        "            \"type\": \"box\",\n",
        "            \"layout\": \"vertical\",\n",
        "            \"contents\": [],\n",
        "            \"margin\": \"sm\"\n",
        "          }\n",
        "        ],\n",
        "        \"flex\": 0\n",
        "        }\n",
        "        }))\n",
        "    \n",
        "change_topic_command_zh = [\n",
        "    '換個話題',\n",
        "]\n",
        "change_topic_command_en = [\n",
        "    'change topic'\n",
        "]\n",
        "\n",
        "def increase_chat_sn(user_id):\n",
        "    GPT3_chat_user_col.update_one({\n",
        "            \"user_id\": user_id\n",
        "        },{\n",
        "            \"$inc\": {'sn': 1}\n",
        "        })\n",
        "\n",
        "def process_command(event, text):\n",
        "    user_id = event.source.user_id\n",
        "    user = get_user(user_id)\n",
        "    \n",
        "    if user['status'] == 'New Starter':\n",
        "        if text == \"我已完成閱讀\":\n",
        "            line_bot_api.reply_message(event.reply_token, \n",
        "               TextSendMessage(text='''偵測到您尚未完成閱讀，請閱讀完所有內容後於最下方點選「開始實驗」，收到頁面告知可以回來才算完成喔！'''))\n",
        "        elif text == \"Ready to go\":\n",
        "            line_bot_api.reply_message(event.reply_token, \n",
        "               TextSendMessage(text='''已更新狀態為 \"Ready to go\"'''))\n",
        "            update_user_status(user['user_id'], \"Ready to go\")\n",
        "        else:\n",
        "            line_bot_api.reply_message(event.reply_token, FlexSendMessage(\n",
        "                alt_text = f\"歡迎來到此聊天機器人實驗，請先點選下方連結閱讀實驗指引並確認開始實驗\\n\\nhttps://exp1.eason.best/starter?id={user_id}\\n\\n完成後請點選「完成」\", \n",
        "                contents = {\n",
        "                \"type\": \"bubble\",\n",
        "                \"hero\": {\n",
        "                \"type\": \"image\",\n",
        "                \"url\": \"https://i.imgur.com/ufIifp6.png\",\n",
        "                \"size\": \"full\",\n",
        "                \"aspectRatio\": \"20:13\",\n",
        "                \"aspectMode\": \"cover\",\n",
        "                },\n",
        "                \"body\": {\n",
        "                \"type\": \"box\",\n",
        "                \"layout\": \"vertical\",\n",
        "                \"contents\": [\n",
        "                  {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"歡迎來到聊天機器人實驗\",\n",
        "                    \"weight\": \"bold\",\n",
        "                    \"size\": \"xl\"\n",
        "                  },\n",
        "                  {\n",
        "                    \"type\": \"box\",\n",
        "                    \"layout\": \"vertical\",\n",
        "                    \"margin\": \"lg\",\n",
        "                    \"spacing\": \"sm\",\n",
        "                    \"contents\": [\n",
        "                      {\n",
        "                        \"type\": \"box\",\n",
        "                        \"layout\": \"baseline\",\n",
        "                        \"spacing\": \"sm\",\n",
        "                        \"contents\": [\n",
        "                          {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": \"點選下方「閱讀指引」觀看實驗說明並勾選同意，之後點選「下一步」開始實驗\",\n",
        "                            \"wrap\": True,\n",
        "                            \"color\": \"#666666\",\n",
        "                            \"size\": \"sm\",\n",
        "                            \"flex\": 5\n",
        "                          }\n",
        "                        ]\n",
        "                      }\n",
        "                    ]\n",
        "                  }\n",
        "                ]\n",
        "                },\n",
        "                \"footer\": {\n",
        "                \"type\": \"box\",\n",
        "                \"layout\": \"vertical\",\n",
        "                \"spacing\": \"sm\",\n",
        "                \"contents\": [\n",
        "                  {\n",
        "                    \"type\": \"button\",\n",
        "                    \"style\": \"link\",\n",
        "                    \"height\": \"sm\",\n",
        "                    \"action\": {\n",
        "                      \"type\": \"uri\",\n",
        "                      \"label\": \"閱讀實驗指引\",\n",
        "                      \"uri\": \"https://exp1.eason.best/starter?id=userid\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"type\": \"button\",\n",
        "                    \"style\": \"link\",\n",
        "                    \"height\": \"sm\",\n",
        "                    \"action\": {\n",
        "                      \"type\": \"message\",\n",
        "                      \"label\": \"下一步\",\n",
        "                      \"text\": \"我已完成閱讀\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"type\": \"box\",\n",
        "                    \"layout\": \"vertical\",\n",
        "                    \"contents\": [],\n",
        "                    \"margin\": \"sm\"\n",
        "                  }\n",
        "                ],\n",
        "                \"flex\": 0\n",
        "                }\n",
        "                }))\n",
        "        return True\n",
        "    elif user['status'] == \"Ready to go\":\n",
        "        # Arrange a group\n",
        "        task_type = randomly_assign_next_task(user)\n",
        "        send_pre_test_info(event, user, task_type)\n",
        "        \n",
        "        \n",
        "        return True\n",
        "    elif text in change_topic_command_zh:\n",
        "        increase_chat_sn(user_id)\n",
        "        line_bot_api.reply_message(event.reply_token, \n",
        "           TextSendMessage(text='''已更換話題，讓我們繼續聊天吧～\\n如果我又持續說重複的話，請輸入「換個話題」以繼續對話'''))\n",
        "        return True\n",
        "    elif text.lower() in change_topic_command_en:\n",
        "        increase_chat_sn(user_id)\n",
        "        line_bot_api.reply_message(event.reply_token, \n",
        "           TextSendMessage(text='''Topic changed, let's continue chatting.\\nIf I keep saying weird things again, please enter 'change topic'.'''))\n",
        "        return True\n",
        "    \n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@app.route(\"/api/v1/line_bot\", methods=['POST'])\n",
        "def callback():\n",
        "    # get X-Line-Signature header value\n",
        "    signature = request.headers['X-Line-Signature']\n",
        "\n",
        "    # get request body as text\n",
        "    body = request.get_data(as_text=True)\n",
        "    app.logger.info(\"Request body: \" + body)\n",
        "\n",
        "    # handle webhook body\n",
        "    try:\n",
        "        handler.handle(body, signature)\n",
        "    except InvalidSignatureError:\n",
        "        print(\"Invalid signature. Please check your channel access token/channel secret.\")\n",
        "        abort(400)\n",
        "\n",
        "    return 'OK'\n",
        "\n",
        "\n",
        "@handler.add(MessageEvent, message=TextMessage)\n",
        "def handleTextMessage(event):\n",
        "    doThreading(process_text_message, args = (event))\n",
        "\n",
        "@handler.add(MessageEvent, message=AudioMessage)\n",
        "def handleAudioMessage(event):\n",
        "    doThreading(process_voice_message, args = (event))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "@app.route(\"/api/v1/status\", methods=['GET'])\n",
        "def get_status():\n",
        "    user_count = GPT3_chat_user_col.estimated_document_count()\n",
        "    chat_count = GPT3_chat_history_col.estimated_document_count()\n",
        "    return {\"user_count\": user_count, \"chat_count\": chat_count}\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "AAA = []\n",
        "if __name__ == \"__main__\":\n",
        "    from flask_cors import CORS\n",
        "    CORS(app)\n",
        "    app.run(port=os.getenv('API_PORT'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2022-08-29T08:17:29.853Z"
        }
      },
      "outputs": [],
      "source": [
        "#os.system('cd ../frontend && rm -rf dist && unzip -qq dist && echo \"Update Frontend Success\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2022-03-27T08:51:27.012Z"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "chatbot",
      "language": "python",
      "name": "chatbot"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
