{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-28T08:44:33.964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:32008/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [28/Aug/2022 16:45:03] \"\u001b[37mPOST /api/v1/line_bot HTTP/1.0\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEEE {'_id': ObjectId('630b293ac7736f70f5af5959'), 'user_id': 'Ub830fb81ec2de64d825b4ab2f6b7472e', 'display_name': '陳怡升 (Eason)', 'bots': ['欠嗆貓', 'Stonk_Guy', 'LLENN', '棒男孩', 'Gawr_Gura'], 'sn': 0}\n",
      "YEEE {'_id': ObjectId('630b293ac7736f70f5af5959'), 'user_id': 'Ub830fb81ec2de64d825b4ab2f6b7472e', 'display_name': '陳怡升 (Eason)', 'bots': ['欠嗆貓', 'Stonk_Guy', 'LLENN', '棒男孩', 'Gawr_Gura'], 'sn': 0}\n",
      "YEEE {'_id': ObjectId('630b293ac7736f70f5af5959'), 'user_id': 'Ub830fb81ec2de64d825b4ab2f6b7472e', 'display_name': '陳怡升 (Eason)', 'bots': ['欠嗆貓', 'Stonk_Guy', 'LLENN', '棒男孩', 'Gawr_Gura'], 'sn': 0}\n",
      "YEEE {'_id': ObjectId('630b293ac7736f70f5af5959'), 'user_id': 'Ub830fb81ec2de64d825b4ab2f6b7472e', 'display_name': '陳怡升 (Eason)', 'bots': ['欠嗆貓', 'Stonk_Guy', 'LLENN', '棒男孩', 'Gawr_Gura'], 'sn': 0}\n",
      "YEEE {'_id': ObjectId('630b293ac7736f70f5af5959'), 'user_id': 'Ub830fb81ec2de64d825b4ab2f6b7472e', 'display_name': '陳怡升 (Eason)', 'bots': ['欠嗆貓', 'Stonk_Guy', 'LLENN', '棒男孩', 'Gawr_Gura'], 'sn': 0}\n",
      "YEEE {'_id': ObjectId('630b293ac7736f70f5af5959'), 'user_id': 'Ub830fb81ec2de64d825b4ab2f6b7472e', 'display_name': '陳怡升 (Eason)', 'bots': ['欠嗆貓', 'Stonk_Guy', 'LLENN', '棒男孩', 'Gawr_Gura'], 'sn': 0}\n",
      "YEEE {'_id': ObjectId('630b293ac7736f70f5af5959'), 'user_id': 'Ub830fb81ec2de64d825b4ab2f6b7472e', 'display_name': '陳怡升 (Eason)', 'bots': ['欠嗆貓', 'Stonk_Guy', 'LLENN', '棒男孩', 'Gawr_Gura'], 'sn': 0}\n",
      "--GPT3 Input/Output--\n",
      "Friend is a cat that reply you with provocative responses:\n",
      "You: test\n",
      "Friend: No comment.\n",
      "You: ?\n",
      "Friend: \n",
      "--GPT3 Input/Output--\n",
      "Friend is a boy that reply you with positive responses:\n",
      "You: ?\n",
      "Friend: Yes, I would love to be friends!\n",
      "--GPT3 Input/Output--\n",
      "Friend is a shark that reply you with humor responses:\n",
      "You: ?\n",
      "Friend: I'm a shark, not a mind reader.\n",
      "--GPT3 Input/Output--\n",
      "Friend is a girl that reply you with cute responses:\n",
      "You: ?\n",
      "Friend: \n",
      "--GPT3 Input/Output--\n",
      "Friend is a business man that reply you with formal responses:\n",
      "You: ?\n",
      "Friend: I'm sorry, I don't understand what you are asking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-64a2bfdb01cc>\", line 396, in thread_GPT3\n",
      "    response_text = translate(response_text_en, target=text_source)['translatedText']\n",
      "  File \"/home/eason/Python/WEB/service/LINE_Bot/2022_09_chatbot_experiment/translate.py\", line 17, in translate\n",
      "    result = translate_client.translate(text, target_language=target)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/translate_v2/client.py\", line 266, in translate\n",
      "    response = self._connection.api_request(method=\"POST\", path=\"\", data=data)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/_http/__init__.py\", line 480, in api_request\n",
      "    raise exceptions.from_http_response(response)\n",
      "google.api_core.exceptions.BadRequest: 400 POST https://translation.googleapis.com/language/translate/v2?prettyPrint=false: Invalid Value\n",
      "\n",
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-64a2bfdb01cc>\", line 396, in thread_GPT3\n",
      "    response_text = translate(response_text_en, target=text_source)['translatedText']\n",
      "  File \"/home/eason/Python/WEB/service/LINE_Bot/2022_09_chatbot_experiment/translate.py\", line 17, in translate\n",
      "    result = translate_client.translate(text, target_language=target)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/translate_v2/client.py\", line 266, in translate\n",
      "    response = self._connection.api_request(method=\"POST\", path=\"\", data=data)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/_http/__init__.py\", line 480, in api_request\n",
      "    raise exceptions.from_http_response(response)\n",
      "google.api_core.exceptions.BadRequest: 400 POST https://translation.googleapis.com/language/translate/v2?prettyPrint=false: Invalid Value\n",
      "\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-64a2bfdb01cc>\", line 396, in thread_GPT3\n",
      "    response_text = translate(response_text_en, target=text_source)['translatedText']\n",
      "  File \"/home/eason/Python/WEB/service/LINE_Bot/2022_09_chatbot_experiment/translate.py\", line 17, in translate\n",
      "    result = translate_client.translate(text, target_language=target)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/translate_v2/client.py\", line 266, in translate\n",
      "    response = self._connection.api_request(method=\"POST\", path=\"\", data=data)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/_http/__init__.py\", line 480, in api_request\n",
      "    raise exceptions.from_http_response(response)\n",
      "google.api_core.exceptions.BadRequest: 400 POST https://translation.googleapis.com/language/translate/v2?prettyPrint=false: Invalid Value\n",
      "\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-64a2bfdb01cc>\", line 396, in thread_GPT3\n",
      "    response_text = translate(response_text_en, target=text_source)['translatedText']\n",
      "  File \"/home/eason/Python/WEB/service/LINE_Bot/2022_09_chatbot_experiment/translate.py\", line 17, in translate\n",
      "    result = translate_client.translate(text, target_language=target)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/translate_v2/client.py\", line 266, in translate\n",
      "    response = self._connection.api_request(method=\"POST\", path=\"\", data=data)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/_http/__init__.py\", line 480, in api_request\n",
      "    raise exceptions.from_http_response(response)\n",
      "google.api_core.exceptions.BadRequest: 400 POST https://translation.googleapis.com/language/translate/v2?prettyPrint=false: Invalid Value\n",
      "\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-64a2bfdb01cc>\", line 396, in thread_GPT3\n",
      "    response_text = translate(response_text_en, target=text_source)['translatedText']\n",
      "  File \"/home/eason/Python/WEB/service/LINE_Bot/2022_09_chatbot_experiment/translate.py\", line 17, in translate\n",
      "    result = translate_client.translate(text, target_language=target)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/translate_v2/client.py\", line 266, in translate\n",
      "    response = self._connection.api_request(method=\"POST\", path=\"\", data=data)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/google/cloud/_http/__init__.py\", line 480, in api_request\n",
      "    raise exceptions.from_http_response(response)\n",
      "google.api_core.exceptions.BadRequest: 400 POST https://translation.googleapis.com/language/translate/v2?prettyPrint=false: Invalid Value\n",
      "\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-64a2bfdb01cc>\", line 331, in process_text_message\n",
      "    send_GPT3_response(text, event)\n",
      "  File \"<ipython-input-2-64a2bfdb01cc>\", line 381, in send_GPT3_response\n",
      "    line_bot_api.reply_message(event.reply_token, message)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/linebot/api.py\", line 110, in reply_message\n",
      "    '/v2/bot/message/reply', data=json.dumps(data), timeout=timeout\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/linebot/api.py\", line 1620, in _post\n",
      "    self.__check_error(response)\n",
      "  File \"/home/eason/anaconda3/envs/chatbot/lib/python3.7/site-packages/linebot/api.py\", line 1661, in __check_error\n",
      "    error=Error.new_from_json_dict(response.json)\n",
      "linebot.exceptions.LineBotApiError: LineBotApiError: status_code=400, request_id=fe274d95-080a-4fd4-a8d6-f208c27f489e, error_response={\"details\": [{\"message\": \"Size must be between 1 and 5\", \"property\": \"messages\"}], \"message\": \"The request body has 1 error(s)\"}, headers={'Content-Type': 'application/json', 'Server': 'envoy', 'x-content-type-options': 'nosniff', 'x-frame-options': 'DENY', 'x-line-request-id': 'fe274d95-080a-4fd4-a8d6-f208c27f489e', 'x-xss-protection': '1; mode=block', 'Content-Length': '122', 'Expires': 'Sun, 28 Aug 2022 08:44:43 GMT', 'Cache-Control': 'max-age=0, no-cache, no-store', 'Pragma': 'no-cache', 'Date': 'Sun, 28 Aug 2022 08:44:43 GMT', 'Connection': 'close'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "load_dotenv('/eason/.server.env')\n",
    "\n",
    "import pymongo\n",
    "MongoClient = pymongo.MongoClient(f\"mongodb://{os.getenv('mongo_user')}:{os.getenv('mongo_pw')}@localhost:27081\")\n",
    "\n",
    "DB_NAME = \"chatbot_experiment_2022_09\"\n",
    "GPT3_chat_history_col = MongoClient[DB_NAME][\"GPT3_Chat\"]\n",
    "GPT3_chat_user_col = MongoClient[DB_NAME][\"Users\"]\n",
    "GPT3_chat_bots_col = MongoClient[DB_NAME][\"Bots\"]\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "from translate import translate\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "from google.cloud import speech\n",
    "import sys, pathlib\n",
    "from pydub import AudioSegment\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "def voice_reco(client, filename):\n",
    "    with io.open(filename, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    audio = speech.RecognitionAudio(content = content)\n",
    "\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"zh-TW\"\n",
    "    )\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    try:\n",
    "        text = response.results[0].alternatives[0].transcript\n",
    "    except:\n",
    "        text = \"\"\n",
    "    return text\n",
    "\n",
    "def process_voice_file(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        # Instantiates a client\n",
    "        client = speech.SpeechClient.from_service_account_json(os.getenv('GOOGLE_SERVICE_JSON_PATH'))\n",
    "        # Detects speech in the audio file\n",
    "        wav = AudioSegment.from_wav(f'{file_path}.wav')\n",
    "        if wav.duration_seconds < 60:\n",
    "            text = voice_reco(client, f'{file_path}.wav')\n",
    "\n",
    "            all_texts = [text]\n",
    "        else:\n",
    "            text = \"too long... can't recognize...\"\n",
    "            wav_files = []\n",
    "            while wav.duration_seconds > 60:\n",
    "                temp_filename = str(uuid.uuid4())\n",
    "                temp_filename = f'{file_path}.wav'\n",
    "                slice_wav = wav[0:59]\n",
    "                slice_wav.export(temp_filename, format=\"wav\")\n",
    "                wav_files.append(temp_filename)\n",
    "                wav = wav[57:]\n",
    "            temp_filename = str(uuid.uuid4())\n",
    "            temp_filename = f'{file_path}.wav'\n",
    "            wav.export(temp_filename, format=\"wav\")\n",
    "            wav_files.append(temp_filename)\n",
    "            all_texts = []\n",
    "            for wav_file in wav_files:\n",
    "                text = voice_reco(client, wav_file)\n",
    "                all_texts.append(text)\n",
    "                os.remove(wav_file)\n",
    "\n",
    "            #response = client.long_running_recognize(config=config, audio=audio)\n",
    "            #response = operation.result(timeout=90)\n",
    "            #text = response.results[0].alternatives[0].transcript\n",
    "        #AAA.append(response)\n",
    "        text = \"\".join(all_texts)\n",
    "        \n",
    "\n",
    "        os.remove(f'{file_path}.wav')\n",
    "        os.remove(f'{file_path}')\n",
    "    except ValueError as e:\n",
    "        import traceback\n",
    "        import sys\n",
    "        exc_type, exc_value, exc_tb = sys.exc_info()\n",
    "        text = \"[ERROR]\\n\" + \"\".join(traceback.format_exception(exc_type, exc_value, exc_tb))\n",
    "        '''if update.message.chat.id in User_List:\n",
    "            result = \"[ERROR]\\n\" + \"\".join(traceback.format_exception(exc_type, exc_value, exc_tb))\n",
    "            bot.edit_message_text(text = result, message_id=reply_msg.message_id, chat_id= reply_msg.chat_id)\n",
    "        else:\n",
    "            result = \"Error, Might be no detectable text in the voice message. If you think this is an error otherwise, please contect the author @EasonC13\"\n",
    "            bot.edit_message_text(text = result, message_id=reply_msg.message_id, chat_id= reply_msg.chat_id)'''\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "import threading\n",
    "import time\n",
    "def doThreading(func, args, waitingTime = 0):\n",
    "    time.sleep(waitingTime)\n",
    "    try:\n",
    "        if len(args) == 1:\n",
    "            t = threading.Thread(target = func, args = (args,))\n",
    "        else:\n",
    "            t = threading.Thread(target = func, args = (args))\n",
    "    except:\n",
    "        t = threading.Thread(target = func, args = (args,))\n",
    "    t.start()\n",
    "    return t\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def process_voice_message(event):\n",
    "    #AAA.append(event)\n",
    "    file_path = f'/tmp/{uuid.uuid4()}'\n",
    "    \n",
    "    message_content = line_bot_api.get_message_content(event.message.id)\n",
    "\n",
    "    with open(file_path, 'wb') as fd:\n",
    "        for chunk in message_content.iter_content():\n",
    "            fd.write(chunk)\n",
    "\n",
    "    subprocess.call(\n",
    "            f'ffmpeg -i {file_path} {file_path}.wav',\n",
    "            shell=True, stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.STDOUT)\n",
    "\n",
    "    text = process_voice_file(file_path)\n",
    "    send_GPT3_response(text = text, event = event)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "from bson.objectid import ObjectId\n",
    "def create_prompt(prompt, prev_msgs, text, num = -3):\n",
    "    prompt = (prompt + \"\\n\") if prompt[-1] != \"\\n\" else prompt\n",
    "    for msg in prev_msgs[num:]:\n",
    "        prompt += f\"You: {msg['input_text_en']}\\nFriend: {msg['response_text_en']}\\n\"\n",
    "    prompt += f\"You: {text}\\nFriend: \"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def get_user(event):\n",
    "    user_profile = line_bot_api.get_profile(event.source.user_id)\n",
    "    \n",
    "    user = GPT3_chat_user_col.find_one({\n",
    "        'user_id': event.source.user_id\n",
    "    })\n",
    "    if user == None:\n",
    "        user = {\n",
    "            'user_id': event.source.user_id,\n",
    "            'display_name': user_profile.display_name,\n",
    "            'bots': ['欠嗆貓', 'Stonk_Guy', 'LLENN', '棒男孩', 'Gawr_Gura'],\n",
    "            'sn': 0\n",
    "        }\n",
    "        GPT3_chat_user_col.insert_one(user)\n",
    "    \n",
    "    print(\"YEEE\", user)\n",
    "    return user\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "#以棄用\n",
    "def update_pre_prompt():\n",
    "    \"\"\"def update_pre_prompt(user_id, text):\n",
    "        GPT3_chat_user_col.update_one({\n",
    "                \"user_id\": user_id\n",
    "            },{\n",
    "                \"$set\": {\"pre_prompt\": text}\n",
    "            })\n",
    "\n",
    "    def update_chat_with(user_id, chat_with, chat_from = \"You\"):\n",
    "        GPT3_chat_user_col.update_one({\n",
    "                \"user_id\": user_id\n",
    "            },{\"$set\":{\n",
    "                \"chat_with\": chat_with,\n",
    "                \"chat_from\": chat_from,\n",
    "            }})\"\"\"\n",
    "pass\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def generate_GPT3_response(event, text, bot):\n",
    "    \n",
    "    user = get_user(event)\n",
    "    \n",
    "    prev_msgs = GPT3_chat_history_col.find({\n",
    "        'user.user_id': event.source.user_id,\n",
    "        'user.sn': user['sn'], #serial number\n",
    "        'bot_id': bot['id'],\n",
    "    })\n",
    "    prev_msgs = list(prev_msgs)\n",
    "    prev_msgs.sort(key=lambda x: x['time'])\n",
    "    \n",
    "    prompt = create_prompt(bot['prefix'], prev_msgs, text, -3)\n",
    "    \n",
    "    have_second_chance = True\n",
    "    max_try = 4\n",
    "\n",
    "    for i in range(max_try):\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"text-davinci-001\",\n",
    "          prompt=prompt,\n",
    "          temperature=0.6 + 0.1*i,\n",
    "          max_tokens=120,\n",
    "          top_p=1.0,\n",
    "          frequency_penalty=0.5 + 0.5 * i,\n",
    "          presence_penalty=0.5 + 0.5 * i,\n",
    "          stop=[\"You:\"]\n",
    "        )\n",
    "\n",
    "        response_text = response.choices[0].text.replace(\"\\n\", \"\")\n",
    "        if i != 0: print(f\"{i}th try  => {response_text}\", end='\\n---\\n')\n",
    "\n",
    "        prev_responses = list(map(lambda x: x['response_text_en'], prev_msgs[-3:]))\n",
    "        count = np.unique(prev_responses, return_counts=True)[1]\n",
    "        if response_text in prev_responses and sum(count>1):\n",
    "            if have_second_chance == True:\n",
    "                have_second_chance = False\n",
    "            elif i == max_try - 2:\n",
    "                #print(\"Last Try\")\n",
    "                prompt = create_prompt(bot['prefix'], [], text, -1)\n",
    "            else:\n",
    "                prompt = create_prompt(bot['prefix'], prev_msgs, text, -1)\n",
    "            #print(\"New Prompt: \", prompt)\n",
    "        else:\n",
    "            break\n",
    "    print(\"--GPT3 Input/Output--\")\n",
    "    print(prompt + response_text, end = '\\n')\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def norm_text(text):\n",
    "    text = text.replace(\"&#39;\", \"'\")\n",
    "    return text\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "from linebot import (\n",
    "    LineBotApi, WebhookHandler\n",
    ")\n",
    "from linebot.exceptions import (\n",
    "    InvalidSignatureError\n",
    ")\n",
    "from linebot.models import (\n",
    "    MessageEvent,\n",
    "    TextMessage,\n",
    "    TextSendMessage,\n",
    "    TemplateSendMessage,\n",
    "    MessageTemplateAction,\n",
    "    ButtonsTemplate,\n",
    "    PostbackEvent,\n",
    "    PostbackTemplateAction,\n",
    "    AudioMessage,\n",
    "    AudioSendMessage,\n",
    "    Sender\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def process_text_message(event):\n",
    "    text = event.message.text\n",
    "    \n",
    "    if process_command(event, text):\n",
    "        return True\n",
    "    \n",
    "    send_GPT3_response(text, event)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "def get_bots(bot_id):\n",
    "    return GPT3_chat_bots_col.find_one({'id': bot_id})\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "def send_GPT3_response(text, event):\n",
    "    \n",
    "    user = get_user(event)\n",
    "    user_profile = line_bot_api.get_profile(event.source.user_id)\n",
    "    \n",
    "    translated_result = translate(text, target=\"en\")\n",
    "    \n",
    "    text_en = translated_result['translatedText']\n",
    "    text_en = norm_text(text_en)\n",
    "    text_source = translated_result['detectedSourceLanguage']\n",
    "    \n",
    "    bots_id = user['bots']\n",
    "    if len(bots_id) == 0:\n",
    "        bots_id = ['棒男孩']\n",
    "    bots = list(map(get_bots, bots_id))\n",
    "    \n",
    "    message = []\n",
    "    tasks = [] #TODO: 如果需要照順序回要改成寫 mapping\n",
    "    for bot in bots:\n",
    "        t = doThreading(thread_GPT3, args = (message, event, text, text_en, bot, user_profile, user, text_source))\n",
    "        tasks.append(t)\n",
    "        #thread_GPT3(message, event, text, text_en, bot, user_profile, user, text_source)\n",
    "    for t in tasks:\n",
    "        t.join()\n",
    "\n",
    "    line_bot_api.reply_message(event.reply_token, message)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "def thread_GPT3(message, event, text, text_en, bot, user_profile, user, text_source):\n",
    "    response_text = \"\"\n",
    "    while response_text == \"\":\n",
    "        response_text_en = generate_GPT3_response(event, text_en, bot)\n",
    "        response_text_en = norm_text(response_text_en)\n",
    "\n",
    "        if text_source[:2] == \"zh\":\n",
    "            response_text = translate(response_text_en, target=\"zh-TW\")['translatedText']\n",
    "        elif text_source != 'en':\n",
    "            response_text = translate(response_text_en, target=text_source)['translatedText']\n",
    "        else:\n",
    "            response_text = response_text_en\n",
    "\n",
    "    print(\"----\")\n",
    "    print(f\"From: {bot['id']}\")\n",
    "    print('--Origin--')\n",
    "    print(f'{text_en} => {response_text_en}')\n",
    "    print('--Translated--')\n",
    "    print(f'{text} => {response_text}')\n",
    "    print('========')\n",
    "\n",
    "\n",
    "    GPT3_chat_history_col.insert_one({\n",
    "        'input_text': text,\n",
    "        'input_text_en': text_en,\n",
    "        'response_text_en': response_text_en,\n",
    "        'response_text': response_text,\n",
    "        'event_message_id': event.message.id,\n",
    "        'user': {\n",
    "            \"display_name\": user_profile.display_name,\n",
    "            \"user_id\": event.source.user_id,\n",
    "            \"sn\": user['sn'],\n",
    "        },\n",
    "        'bot_id': bot['id'],\n",
    "        \"time\": datetime.datetime.now(),\n",
    "        \"input_type\": 'text',\n",
    "    })\n",
    "\n",
    "    message.append(\n",
    "        TextSendMessage(\n",
    "            text=response_text, \n",
    "            sender = Sender(name = bot['name'].replace(\"_\", \" \"),\n",
    "                            icon_url = bot['img_url']))\n",
    "            )\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "change_topic_command_zh = [\n",
    "    '換個話題',\n",
    "]\n",
    "change_topic_command_en = [\n",
    "    'change topic'\n",
    "]\n",
    "\n",
    "def increase_chat_sn(user_id):\n",
    "    GPT3_chat_user_col.update_one({\n",
    "            \"user_id\": user_id\n",
    "        },{\n",
    "            \"$inc\": {'sn': 1}\n",
    "        })\n",
    "\n",
    "def process_command(event, text):\n",
    "    user_id = event.source.user_id\n",
    "    user = get_user(event)\n",
    "    \n",
    "    if text in change_topic_command_zh:\n",
    "        increase_chat_sn(user_id)\n",
    "        line_bot_api.reply_message(event.reply_token, \n",
    "           TextSendMessage(text='''已更換話題，讓我們繼續聊天吧～\\n如果我又持續說重複的話，請輸入「換個話題」以繼續對話'''))\n",
    "        return True\n",
    "    elif text in change_topic_command_en:\n",
    "        increase_chat_sn(user_id)\n",
    "        line_bot_api.reply_message(event.reply_token, \n",
    "           TextSendMessage(text='''Topic changed, let's continue chatting.\\nIf I keep saying weird things again, please enter 'change topic'.'''))\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "from flask import Flask, request, abort, render_template, send_from_directory\n",
    "import subprocess\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__, template_folder = 'dist')\n",
    "\n",
    "line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))\n",
    "handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))\n",
    "\n",
    "\n",
    "\n",
    "@app.route(\"/api/v1/line_bot\", methods=['POST'])\n",
    "def callback():\n",
    "    # get X-Line-Signature header value\n",
    "    signature = request.headers['X-Line-Signature']\n",
    "\n",
    "    # get request body as text\n",
    "    body = request.get_data(as_text=True)\n",
    "    app.logger.info(\"Request body: \" + body)\n",
    "\n",
    "    # handle webhook body\n",
    "    try:\n",
    "        handler.handle(body, signature)\n",
    "    except InvalidSignatureError:\n",
    "        print(\"Invalid signature. Please check your channel access token/channel secret.\")\n",
    "        abort(400)\n",
    "\n",
    "    return 'OK'\n",
    "\n",
    "\n",
    "@handler.add(MessageEvent, message=TextMessage)\n",
    "def handleTextMessage(event):\n",
    "    doThreading(process_text_message, args = (event))\n",
    "\n",
    "@handler.add(MessageEvent, message=AudioMessage)\n",
    "def handleAudioMessage(event):\n",
    "    doThreading(process_voice_message, args = (event))\n",
    "    \n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "@app.route(\"/api/v1/status\", methods=['GET'])\n",
    "def get_status():\n",
    "    user_count = GPT3_chat_user_col.estimated_document_count()\n",
    "    chat_count = GPT3_chat_history_col.estimated_document_count()\n",
    "    return {\"user_count\": user_count, \"chat_count\": chat_count}\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "AAA = []\n",
    "if __name__ == \"__main__\":\n",
    "    from flask_cors import CORS\n",
    "    CORS(app)\n",
    "    app.run(port=os.getenv('API_PORT'))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
